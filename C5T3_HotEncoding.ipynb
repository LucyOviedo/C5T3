{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy,pandas,scipy, math, matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from math import sqrt\n",
    "\n",
    "#model metrics\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Estimators\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# RFE \n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Hot encoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##         Import and Prepare the Data          ##\n",
    "##################################################\n",
    "\n",
    "rawDefaultCredit= pd.read_csv('dataset/default of credit card clients.csv', header =1)\n",
    "\n",
    "# Data and Text Cleaning\n",
    "\n",
    "# ID: represents the number of the observation and has no value, needs to get removed\n",
    "rawDefaultCredit= rawDefaultCredit.drop(\"ID\", axis=1)\n",
    "\n",
    "# PAY_0 should be renamed PAY_1\n",
    "# (the inplace parameter will change the dataframe without assignment)\n",
    "rawDefaultCredit.rename(columns={\"PAY_0\": \"PAY_1\"}, inplace=True)\n",
    "\n",
    "# Default Payment next month (not standard name needs to get renamed)\n",
    "rawDefaultCredit.rename(columns={\"default payment next month\": \"DEFAULT\"}, inplace=True)\n",
    "\n",
    "# Replace 4, 5, 6 to 0 to unify others to one unique value\n",
    "rawDefaultCredit['EDUCATION'].replace([0, 5, 6], [4, 4, 4], inplace=True)\n",
    "\n",
    "rawDefaultCredit.to_csv('dataset/defaultCreditCardClients.csv')\n",
    "\n",
    "defaultCredit = rawDefaultCredit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultCredit['DEFAULT'] = defaultCredit['DEFAULT'].astype('category')\n",
    "defaultCredit['SEX'] = defaultCredit['SEX'].astype('category')\n",
    "defaultCredit['EDUCATION'] = defaultCredit['EDUCATION'].astype('category')\n",
    "defaultCredit['MARRIAGE'] = defaultCredit['MARRIAGE'].astype('category')\n",
    "defaultCredit['PAY_1'] = defaultCredit['PAY_1'].astype('category')\n",
    "defaultCredit['PAY_2'] = defaultCredit['PAY_2'].astype('category')\n",
    "defaultCredit['PAY_3'] = defaultCredit['PAY_3'].astype('category')\n",
    "defaultCredit['PAY_4'] = defaultCredit['PAY_4'].astype('category')\n",
    "defaultCredit['PAY_5'] = defaultCredit['PAY_5'].astype('category')\n",
    "defaultCredit['PAY_6'] = defaultCredit['PAY_6'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot Encoding\n",
    "df = defaultCredit\n",
    "#X = allFeatures\n",
    "cat_columns = ['SEX', 'EDUCATION', 'MARRIAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 1.0, 0.0, ..., 0, 0, 1],\n",
       "       [1.0, 1.0, 0.0, ..., 0, 2000, 1],\n",
       "       [1.0, 1.0, 0.0, ..., 1000, 5000, 0],\n",
       "       ...,\n",
       "       [0.0, 1.0, 0.0, ..., 2000, 3100, 1],\n",
       "       [0.0, 0.0, 1.0, ..., 52964, 1804, 1],\n",
       "       [0.0, 1.0, 0.0, ..., 1000, 1000, 1]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use when different features need different preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "col_transformer = make_column_transformer(\n",
    "        (OneHotEncoder(drop='first'), cat_columns),\n",
    "        remainder='passthrough')\n",
    "\n",
    "X_ohe = col_transformer.fit_transform(defaultCredit)\n",
    "X_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GradientBoostingClassifier\n",
      "Accuracy: 100.0000%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5873\n",
      "           1       1.00      1.00      1.00      1627\n",
      "\n",
      "    accuracy                           1.00      7500\n",
      "   macro avg       1.00      1.00      1.00      7500\n",
      "weighted avg       1.00      1.00      1.00      7500\n",
      "\n",
      "Cross Validation: [1. 1. 1. 1. 1.]\n",
      "Score: 1.0\n",
      "Log Loss: 1.4877390396612129e-05\n",
      "============================================================\n",
      "AdaBoostClassifier\n",
      "Accuracy: 100.0000%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5873\n",
      "           1       1.00      1.00      1.00      1627\n",
      "\n",
      "    accuracy                           1.00      7500\n",
      "   macro avg       1.00      1.00      1.00      7500\n",
      "weighted avg       1.00      1.00      1.00      7500\n",
      "\n",
      "Cross Validation: [1. 1. 1. 1. 1.]\n",
      "Score: 1.0\n",
      "Log Loss: 9.992007221626413e-16\n",
      "============================================================\n",
      "RandomForestClassifier\n",
      "Accuracy: 89.8667%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      5873\n",
      "           1       1.00      0.53      0.70      1627\n",
      "\n",
      "    accuracy                           0.90      7500\n",
      "   macro avg       0.94      0.77      0.82      7500\n",
      "weighted avg       0.91      0.90      0.89      7500\n",
      "\n",
      "Cross Validation: [1.         0.88044444 0.87622222 0.87222222 1.        ]\n",
      "Score: 0.8932444444444444\n",
      "Log Loss: 0.2404762064210678\n",
      "============================================================\n",
      "LinearDiscriminantAnalysis\n",
      "Accuracy: 81.3067%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      5873\n",
      "           1       0.68      0.26      0.38      1627\n",
      "\n",
      "    accuracy                           0.81      7500\n",
      "   macro avg       0.75      0.61      0.63      7500\n",
      "weighted avg       0.79      0.81      0.78      7500\n",
      "\n",
      "Cross Validation: [0.80977778 0.814      0.81222222 0.816      0.80777778]\n",
      "Score: 0.8124444444444444\n",
      "Log Loss: 0.4590669029411625\n",
      "============================================================\n",
      "KNeighborsClassifier\n",
      "Accuracy: 76.9733%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.87      5873\n",
      "           1       0.39      0.11      0.17      1627\n",
      "\n",
      "    accuracy                           0.77      7500\n",
      "   macro avg       0.59      0.53      0.52      7500\n",
      "weighted avg       0.71      0.77      0.72      7500\n",
      "\n",
      "Cross Validation: [0.76711111 0.76355556 0.76711111 0.76666667 0.76422222]\n",
      "Score: 0.8437777777777777\n",
      "Log Loss: 5.302479646001527\n",
      "============================================================\n",
      "DecisionTreeClassifier\n",
      "Accuracy: 100.0000%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5873\n",
      "           1       1.00      1.00      1.00      1627\n",
      "\n",
      "    accuracy                           1.00      7500\n",
      "   macro avg       1.00      1.00      1.00      7500\n",
      "weighted avg       1.00      1.00      1.00      7500\n",
      "\n",
      "Cross Validation: [1. 1. 1. 1. 1.]\n",
      "Score: 1.0\n",
      "Log Loss: 9.992007221626413e-16\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#Dependent Variable Training Set (y Training)\n",
    "depVar = defaultCredit['DEFAULT']\n",
    "\n",
    "#Training Data is divided into two parts: X-train and y_train\n",
    "#Testing data follows the same rules and contains two sets: X_test and y_test (ground truth)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ohe, depVar, test_size=0.25, random_state=123)\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Classification Report\", \"Cross validation\", \"Score\", \"LogLoss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    GradientBoostingClassifier(max_depth=2),      #82.2267%\n",
    "    AdaBoostClassifier(),              #81.8000%\n",
    "    RandomForestClassifier(max_depth=2, n_estimators=50, max_features=\"auto\"),  #81.5600%\n",
    "    LinearDiscriminantAnalysis(),                 #81.2267%\n",
    "    KNeighborsClassifier(n_neighbors=2),          #76.4400%\n",
    "    DecisionTreeClassifier(max_depth=2),           #72.6000%\n",
    "#    SVC(gamma=2, C=1, probability=True),  #78.2533% Takes a long time to run\n",
    "]\n",
    "\n",
    "for clf in classifiers:\n",
    "    print(\"=\"*60)\n",
    "    name = clf.__class__.__name__\n",
    "    print(name)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "     \n",
    "    class_rep = classification_report(y_test, train_predictions )\n",
    "    print(\"Classification Report:\\n {}\".format(class_rep))\n",
    "     \n",
    "    cross_val = cross_val_score(clf, X_train, y_train)\n",
    "    print(\"Cross Validation: {}\".format(cross_val))\n",
    "    \n",
    "    #score\n",
    "    score = clf.score(X_train,y_train)\n",
    "    print(\"Score: {}\".format(score))\n",
    "    \n",
    "    #Predictions\n",
    "    train_predictions_proba = clf.predict_proba(X_test)\n",
    "    ll = log_loss(y_test, train_predictions_proba)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, class_rep, cross_val, score, ll]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
